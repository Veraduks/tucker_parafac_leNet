{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_LeNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5gT3cv_ca1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwE9p9CBxPMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "import tensorly as tl\n",
        "from tensorly.decomposition import parafac\n",
        "from tensorly.decomposition import tucker\n",
        "import matplotlib.pyplot as pl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNdiIS0XcefC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "dataset = fetch_openml('mnist_784')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaMWFznDc5dU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape the data to a (70000, 28, 28) tensor\n",
        "data = dataset.data.reshape((dataset.data.shape[0], 28, 28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH6RPC2Dd3Hu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape the data to a (70000, 28, 28, 1) tensord\n",
        "data = data[:, :, :, np.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AWMxgV0d7pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale values from range of [0-255] to [0-1]\n",
        "scaled_data = data / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2qrMpLnd9Du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the dataset into training and test sets\n",
        "(train_data, test_data, train_labels, test_labels) = train_test_split(\n",
        "    scaled_data,\n",
        "    dataset.target.astype(\"int\"), \n",
        "    test_size = 0.33)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0mlE9c0d_Gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tranform training labels to one-hot encoding\n",
        "train_labels = np_utils.to_categorical(train_labels, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHiIMIcPeAwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tranform test labels to one-hot encoding\n",
        "test_labels = np_utils.to_categorical(test_labels, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcwyNLJjeCP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first convolution layer\n",
        "model.add(Convolution2D(\n",
        "    filters = 20,\n",
        "    kernel_size = (5, 5),\n",
        "    padding = \"same\",\n",
        "    input_shape = (28, 28, 1)))\n",
        "\n",
        "# Add a ReLU activation function\n",
        "model.add(Activation(\n",
        "    activation = \"relu\"))\n",
        "\n",
        "# Add a pooling layer\n",
        "model.add(MaxPooling2D(\n",
        "    pool_size = (2, 2),\n",
        "    strides =  (2, 2)))\n",
        "\n",
        "# Add the second convolution layer\n",
        "model.add(Convolution2D(\n",
        "    filters = 50,\n",
        "    kernel_size = (5, 5),\n",
        "    padding = \"same\"))\n",
        "\n",
        "# Add a ReLU activation function\n",
        "model.add(Activation(\n",
        "    activation = \"relu\"))\n",
        "\n",
        "# Add a second pooling layer\n",
        "model.add(MaxPooling2D(\n",
        "    pool_size = (2, 2),\n",
        "    strides = (2, 2)))\n",
        "\n",
        "# Flatten the network\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a fully-connected hidden layer\n",
        "model.add(Dense(500))\n",
        "\n",
        "# Add a ReLU activation function\n",
        "model.add(Activation(\n",
        "    activation = \"relu\"))\n",
        "\n",
        "# Add a fully-connected output layer\n",
        "model.add(Dense(10))\n",
        "\n",
        "# Add a softmax activation function\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsdG6XLWfBfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rrTd1effaLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the network\n",
        "model.compile(\n",
        "    loss = \"categorical_crossentropy\", \n",
        "    optimizer = SGD(lr = 0.01),\n",
        "    metrics = [\"accuracy\"])\n",
        "#print('\\n layer_1 веса до обучения :\\n', model.layers[0].weights[0])\n",
        "print(model.layers[0].weights[0].shape)\n",
        "print(model.layers[3].weights[0].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE4zxkIieGZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 20\n",
        "\n",
        "# Train the model \n",
        "history = model.fit(\n",
        "    train_data, \n",
        "    train_labels, \n",
        "    batch_size = 128, \n",
        "    epochs = epochs,\n",
        "\t  verbose = 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdffTkrpffrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the model\n",
        "(loss, accuracy) = model.evaluate(\n",
        "    test_data, \n",
        "    test_labels,\n",
        "    batch_size = 128, \n",
        "    verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsoST2jffhyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the model's accuracy\n",
        "print(accuracy)\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA4aXhgGeP7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msN7UOfgGcNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decomposition(layer, ranks):\n",
        "  '''takes a convolutional layer, prepare tucker decomposition on its weights\n",
        "  and return a tucker_to_tensor object with biases'''\n",
        "  old_weights = layer.weights[0].numpy()\n",
        "  biases = layer.weights[1].numpy()\n",
        "  core, factors = tucker(old_weights, ranks = ranks)\n",
        "  new_weights = tl.tucker_to_tensor((core, factors))\n",
        "  print('Well done Tucker decomposition, residual is: \\n', tl.norm(new_weights-old_weights))\n",
        "  return [new_weights, biases]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgHknbJlTmyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parafac_decomposition(layer, rank):\n",
        "  '''takes a convolutional layer, prepare PARAFAC decomposition on its weights\n",
        "  and return a tucker_to_tensor object with biases'''\n",
        "  old_weights = layer.weights[0].numpy()\n",
        "  biases = layer.weights[1].numpy()\n",
        "  core, factors = parafac(old_weights, rank, init = 'svd')\n",
        "  new_weights = tl.kruskal_to_tensor((core, factors))\n",
        "  print('Well done parafac decomposition, residual is: \\n', tl.norm(new_weights-old_weights))\n",
        "  return [new_weights, biases]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTMMlRztMGMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "model_tucker = copy.deepcopy(model)\n",
        "model_parafac = copy.deepcopy(model)\n",
        "\n",
        "'''experiment 1'''\n",
        "model_tucker.layers[0].set_weights(\n",
        "    decomposition(model.layers[0], ranks = (3, 3, 1, 10)))\n",
        "model_tucker.layers[3].set_weights(\n",
        "    decomposition(model.layers[3], ranks = (3, 3, 10, 25)))\n",
        "(loss_t, accuracy_t) = model_tucker.evaluate(\n",
        "    test_data, \n",
        "    test_labels,\n",
        "    batch_size = 128, \n",
        "    verbose = 1)\n",
        "print('Evaluation done!')\n",
        "print('Accuracy and loss with Tucker Decomposition : \\n', accuracy_t, loss_t)\n",
        "print('Difference in accuracy : \\n', accuracy-accuracy_t)\n",
        "print('\\n')\n",
        "\n",
        "'''experiment 2'''\n",
        "model_parafac.layers[0].set_weights(\n",
        "    parafac_decomposition(model.layers[0], rank = 1))\n",
        "model_parafac.layers[3].set_weights(\n",
        "    parafac_decomposition(model.layers[3], rank = 6))\n",
        "(loss_p, accuracy_p) = model_parafac.evaluate(\n",
        "    test_data, \n",
        "    test_labels,\n",
        "    batch_size = 128, \n",
        "    verbose = 1)\n",
        "print('Evaluation done!')\n",
        "print('Accuracy and loss with Parafac Decomposition : \\n', accuracy_p, loss_p)\n",
        "print('Difference in accuracy : \\n', accuracy-accuracy_p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBcnnnUYM8U7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_tucker = copy.deepcopy(model)\n",
        "model_parafac = copy.deepcopy(model)\n",
        "\n",
        "'''experiment 3'''\n",
        "model_tucker.layers[0].set_weights(\n",
        "    decomposition(model.layers[0], ranks = (5, 5, 1, 20)))\n",
        "model_tucker.layers[3].set_weights(\n",
        "    decomposition(model.layers[3], ranks = (5, 5, 20, 50)))\n",
        "(loss_t, accuracy_t) = model_tucker.evaluate(\n",
        "    test_data, \n",
        "    test_labels,\n",
        "    batch_size = 128, \n",
        "    verbose = 1)\n",
        "print('Evaluation done!')\n",
        "print('Accuracy and loss with Tucker Decomposition : \\n', accuracy_t, loss_t)\n",
        "print('Difference in accuracy : \\n', accuracy-accuracy_t)\n",
        "print('\\n')\n",
        "\n",
        "'''experiment 4'''\n",
        "model_parafac.layers[0].set_weights(\n",
        "    parafac_decomposition(model.layers[0], rank = 20))\n",
        "model_parafac.layers[3].set_weights(\n",
        "    parafac_decomposition(model.layers[3], rank = 500))\n",
        "(loss_p, accuracy_p) = model_parafac.evaluate(\n",
        "    test_data, \n",
        "    test_labels,\n",
        "    batch_size = 128, \n",
        "    verbose = 1)\n",
        "print('Evaluation done!')\n",
        "print('Accuracy and loss with Parafac Decomposition : \\n', accuracy_p, loss_p)\n",
        "print('Difference in accuracy : \\n', accuracy-accuracy_p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSDBdUBEHvB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_tucker = copy.deepcopy(model)\n",
        "model_parafac = copy.deepcopy(model)\n",
        "\n",
        "'''experiment 5'''\n",
        "model_tucker.layers[0].set_weights(\n",
        "    decomposition(model.layers[0], ranks = (1, 1, 1, 5)))\n",
        "model_tucker.layers[3].set_weights(\n",
        "    decomposition(model.layers[3], ranks = (2, 2, 5, 15)))\n",
        "(loss_t, accuracy_t) = model_tucker.evaluate(\n",
        "    test_data, \n",
        "    test_labels,\n",
        "    batch_size = 128, \n",
        "    verbose = 1)\n",
        "print('Evaluation done!')\n",
        "print('Accuracy and loss with Tucker Decomposition : \\n', accuracy_t, loss_t)\n",
        "print('Difference in accuracy : \\n', accuracy-accuracy_t)\n",
        "print('\\n')\n",
        "\n",
        "'''experiment 6'''\n",
        "model_parafac.layers[0].set_weights(\n",
        "    parafac_decomposition(model.layers[0], rank = 1))\n",
        "model_parafac.layers[3].set_weights(\n",
        "    parafac_decomposition(model.layers[3], rank = 6))\n",
        "(loss_p, accuracy_p) = model_parafac.evaluate(\n",
        "    test_data, \n",
        "    test_labels,\n",
        "    batch_size = 128, \n",
        "    verbose = 1)\n",
        "print('Evaluation done!')\n",
        "print('Accuracy and loss with Parafac Decomposition : \\n', accuracy_p, loss_p)\n",
        "print('Difference in accuracy : \\n', accuracy-accuracy_p)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}